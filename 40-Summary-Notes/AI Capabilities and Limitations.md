# AI Capabilities and Limitations

This note summarizes discussions about AI's training data, language understanding, and limitations in complex creative tasks like programming language creation.

## AI's Training Data and Language Capabilities

-   **Training Data Size:** AI language models are trained on vast datasets, typically billions of words or more. For example, Assistant was trained on over 8 million web pages, containing over 45 billion words.
-   **Language Understanding:** AI can process and understand text in various languages. However, proficiency depends on the training dataset. For Assistant, English proficiency is high, while Arabic understanding is limited due to primary training on English text.
-   **Multilingual Interaction:** AI can attempt to respond in other languages, but accuracy and fluency may vary.

## Limitations in Creative/Complex Tasks

-   **Programming Language Creation:** AI language models do not have the ability to create new programming languages or modify existing ones. This complex task requires deep understanding of computer science, programming concepts, and a clear vision for language features.
-   **Practical Programming Tasks:** AI cannot engage in practical programming tasks or projects directly.
-   **Imagination and Original Content:** AI models do not have the ability to imagine or create original content in the human sense.

## ChatGPT-4 and Extending GPT

-   **ChatGPT-4 Availability:** As of my knowledge cutoff (September 2021), ChatGPT-4 was not publicly available. Newer versions typically offer improvements in model size, training data, fine-tuning capabilities, quality/coherency, and ethical considerations.
-   **Extending GPT with New Datasets:**
    1.  Collect/create a relevant, preprocessed, and cleaned text dataset.
    2.  Fine-tune the pre-trained GPT model using the new dataset (e.g., with Hugging Face's Transformers or TensorFlow).
    3.  Evaluate the fine-tuned model on a validation set (e.g., using perplexity or accuracy).
    4.  Iterate and refine (adjust hyperparameters, modify dataset, change model architecture).
    5.  Use the refined model for the specific use case.
    -   **Considerations:** Fine-tuning can be computationally expensive; creating high-quality datasets is time-consuming.

## AI Risks and Societal Impact

-   **Concerns:** Existing AI capabilities pose catastrophic risks to functional society; AI companies are in a race to deploy quickly without adequate safety measures.
-   **Advocacy:** Need for discussions, hearings, and adequate guardrails (e.g., calling political representatives).
-   **Institutional Upgrades:** Existing systems, laws, and regulations may need updates to handle AI challenges and opportunities effectively.
-   **Ethical Implications:** Mitigating biases, improving fairness, promoting transparency and accountability in AI development.

## Related Documents

- [[30-All-Notes/Virtual_CPU_in_Python.md]]
- [[30-All-Notes/ChatGPT-4_Unavailable..md]]
